{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature and Features List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_utils.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.data_utils.preprocessing import *\n",
    "from relax.data_utils.transforms import *\n",
    "from relax.utils import get_config, gumbel_softmax, load_pytree, save_pytree\n",
    "from relax.import_essentials import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import sklearn.preprocessing as skp\n",
    "from fastcore.test import test_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Feature:\n",
    "    \"\"\"THe feature class which represents a column in the dataset.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        data: np.ndarray,\n",
    "        transformation: str | BaseTransformation | dict,\n",
    "        transformed_data = None,\n",
    "        is_immutable: bool = False,\n",
    "        is_categorical: bool = None,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self._data = data\n",
    "        self._transformation = self._dispatch_transformation(transformation)\n",
    "        self._transformed_data = transformed_data\n",
    "        self._is_immutable = is_immutable\n",
    "        self._is_categorical = self._init_is_categorical(is_categorical)\n",
    "\n",
    "    def with_transformed_data(\n",
    "        self,\n",
    "        transformed_data: np.ndarray,\n",
    "        **kwargs        \n",
    "    ) -> Feature:\n",
    "        \"\"\"Create a new feature with transformed data.\"\"\"\n",
    "        \n",
    "        org_data = self.inverse_transform(transformed_data)\n",
    "        return Feature(\n",
    "            name=self.name,\n",
    "            data=org_data,\n",
    "            transformation=self.transformation,\n",
    "            transformed_data=transformed_data,\n",
    "            is_immutable=self.is_immutable,\n",
    "            is_categorical=self.is_categorical,\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def data(self) -> jax.Array:\n",
    "        return self._data\n",
    "    \n",
    "    @property\n",
    "    def is_immutable(self) -> bool:\n",
    "        return self._is_immutable\n",
    "    \n",
    "    @property\n",
    "    def transformation(self) -> BaseTransformation:\n",
    "        return self._transformation\n",
    "    \n",
    "    @property\n",
    "    def is_categorical(self) -> bool:\n",
    "        return self._is_categorical\n",
    "\n",
    "    @property\n",
    "    def transformed_data(self) -> jax.Array:\n",
    "        if self._transformed_data is None:\n",
    "            return self.fit_transform(self.data)\n",
    "        else:\n",
    "            return self._transformed_data\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, d):\n",
    "        return cls(**d)\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'data': self.data,\n",
    "            'transformed_data': self.transformed_data,\n",
    "            'transformation': self.transformation.to_dict(),\n",
    "            'is_immutable': self.is_immutable,\n",
    "            'is_categorical': self.is_categorical,\n",
    "        }\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Feature(\" + \",\\n\".join([\n",
    "            f\"{k}={v}\" for k, v in self.to_dict().items()]) + \")\"\n",
    "    \n",
    "    __str__ = __repr__\n",
    "\n",
    "    def __get_item__(self, idx):\n",
    "        return self.to_dict().update({\n",
    "            'data': self.data[idx],\n",
    "            'transformed_data': self.transformed_data[idx],\n",
    "        })\n",
    "    \n",
    "    def _dispatch_transformation(self, transformation: str | dict | BaseTransformation):\n",
    "        T = FEATURE_TRANSFORMATIONS\n",
    "        if isinstance(transformation, str):\n",
    "            if transformation not in T.keys():\n",
    "                raise ValueError(f\"Unknown transformation: {transformation}\")\n",
    "            return T[transformation]()\n",
    "        elif isinstance(transformation, dict):\n",
    "            # TODO: only supported transformation can be used for serialization\n",
    "            t_name = transformation['name']\n",
    "            if t_name not in T.keys():\n",
    "                raise ValueError(\"Only supported transformation can be inited from dict. \"\n",
    "                                 f\"Got {t_name}, but should be one of {T.keys()}.\")\n",
    "            return T[t_name]().from_dict(transformation)\n",
    "        elif isinstance(transformation, BaseTransformation):\n",
    "            return deepcopy(transformation)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown transformation: {transformation}\")\n",
    "        \n",
    "    def _init_is_categorical(self, is_categorical: bool = None):\n",
    "        if is_categorical is None:\n",
    "            return self.transformation.is_categorical\n",
    "        else:\n",
    "            if hasattr(self, '_is_categorical'):\n",
    "                assert self.is_categorical == is_categorical\n",
    "            return is_categorical\n",
    "\n",
    "    def set_transformation(self, transformation: str | dict | BaseTransformation) -> Feature:\n",
    "        self._transformation = self._dispatch_transformation(transformation)\n",
    "        self._is_categorical = self._init_is_categorical()\n",
    "        self._transformed_data = None # Reset transformed data\n",
    "        return self\n",
    "    \n",
    "    def fit(self):\n",
    "        self.transformation.fit(self.data)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, xs):\n",
    "        return self.transformation.transform(xs)\n",
    "\n",
    "    def fit_transform(self, xs):\n",
    "        return self.transformation.fit_transform(xs)\n",
    "    \n",
    "    def inverse_transform(self, xs):\n",
    "        return self.transformation.inverse_transform(xs)\n",
    "    \n",
    "    def apply_constraints(self, xs, cfs, hard: bool = False, rng_key=None, **kwargs):\n",
    "        return jax.lax.cond(\n",
    "            self.is_immutable,\n",
    "            true_fun=lambda xs: jnp.broadcast_to(xs, cfs.shape),\n",
    "            false_fun=lambda _: self.transformation.apply_constraints(xs, cfs, hard=hard, rng_key=rng_key, **kwargs),\n",
    "            operand=xs,\n",
    "        )\n",
    "    \n",
    "    def compute_reg_loss(self, xs, cfs, hard: bool = False):\n",
    "        return self.transformation.compute_reg_loss(xs, cfs, hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cont = Feature(\n",
    "    name='continuous',\n",
    "    data=np.random.randn(100, 1),\n",
    "    transformation='minmax',\n",
    "    is_immutable=False,\n",
    ")\n",
    "assert feat_cont.transformed_data.shape == (100, 1)\n",
    "assert feat_cont.transformed_data.min() >= 0\n",
    "assert feat_cont.transformed_data.max() <= 1\n",
    "assert jnp.allclose(\n",
    "    feat_cont.inverse_transform(feat_cont.transformed_data), feat_cont.data)\n",
    "assert feat_cont.is_categorical is False\n",
    "\n",
    "feat_cont_1 = feat_cont.with_transformed_data(feat_cont.transformed_data)\n",
    "assert isinstance(feat_cont_1, Feature)\n",
    "assert feat_cont_1 is not feat_cont\n",
    "assert np.allclose(\n",
    "    feat_cont_1.data, feat_cont.data\n",
    ")\n",
    "assert feat_cont.transformation.to_dict() == feat_cont_1.transformation.to_dict()\n",
    "\n",
    "feat_cat = Feature(\n",
    "    name='category',\n",
    "    data=np.random.choice(['a', 'b', 'c'], size=(100, 1)),\n",
    "    transformation='ohe',\n",
    "    is_immutable=False,\n",
    ")\n",
    "assert feat_cat.transformed_data.shape == (100, 3)\n",
    "assert np.all(feat_cat.inverse_transform(feat_cat.transformed_data) == feat_cat.data)\n",
    "assert feat_cat.is_categorical\n",
    "\n",
    "feat_cat_1 = feat_cat.with_transformed_data(jax.nn.one_hot(jnp.array([0, 1, 2, 0, 1, 2]), 3))\n",
    "assert feat_cat_1 is not feat_cat\n",
    "assert np.array_equal(\n",
    "    feat_cat_1.data, np.array(['a', 'b', 'c', 'a', 'b', 'c']).reshape(-1, 1)\n",
    ") \n",
    "\n",
    "# Test serialization\n",
    "d = feat_cont.to_dict()\n",
    "feat_cont_1 = Feature.from_dict(d)\n",
    "assert feat_cont_1.name == feat_cont.name\n",
    "assert np.allclose(feat_cont_1.data, feat_cont.data)\n",
    "assert np.allclose(feat_cont_1.transformed_data, feat_cont.transformed_data)\n",
    "assert feat_cont_1.is_immutable == feat_cont.is_immutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set_transformation\n",
    "feat_cat = Feature(\n",
    "    name='category',\n",
    "    data=np.random.choice(['a', 'b', 'c'], size=(100, 1)),\n",
    "    transformation='ohe',\n",
    "    is_immutable=False,\n",
    ")\n",
    "assert feat_cat.transformation.name == 'ohe'\n",
    "assert feat_cat.transformed_data.shape == (100, 3)\n",
    "feat_cat.set_transformation('ordinal')\n",
    "assert feat_cat.transformation.name == 'ordinal'\n",
    "assert feat_cat.is_categorical\n",
    "assert feat_cat.transformed_data.shape == (100, 1)\n",
    "assert feat_cat.is_immutable is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FeaturesList:\n",
    "    def __init__(\n",
    "        self,\n",
    "        features: list[Feature] | FeaturesList,\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        if isinstance(features, FeaturesList):\n",
    "            self._features = features.features\n",
    "            self._feature_indices = features.feature_indices\n",
    "            self._transformed_data = features.transformed_data\n",
    "        elif isinstance(features, Feature):\n",
    "            self._features = [features]\n",
    "        elif isinstance(features, list):\n",
    "            if len(features) > 0 and not isinstance(features[0], Feature):\n",
    "                raise ValueError(f\"Invalid features type: {type(features[0]).__name__}\")\n",
    "            self._features = features\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown features type. Got {type(features).__name__}\")\n",
    "        \n",
    "        # Record the current position of the features\n",
    "        self.pose = 0\n",
    "\n",
    "    # Iterator\n",
    "    def __len__(self):\n",
    "        return len(self._features)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.pose < len(self):\n",
    "            feat = self._features[self.pose]\n",
    "            self.pose += 1\n",
    "            return feat\n",
    "        else:\n",
    "            self.pose = 0\n",
    "            raise StopIteration\n",
    "        \n",
    "    # Indexing\n",
    "    def __getitem__(self, idx: str | list[str]) -> Feature | list[Feature]:\n",
    "        if not hasattr(self, \"_feature_name_list_indices\"):\n",
    "            self._feature_name_list_indices = {feat.name: i for i, feat in enumerate(self._features)}\n",
    "        indices = self._feature_name_list_indices\n",
    "        if isinstance(idx, str):\n",
    "            if idx not in indices:\n",
    "                raise ValueError(f\"Invalid feature name: {idx}\")\n",
    "            return self._features[indices[idx]]\n",
    "        elif isinstance(idx, list):\n",
    "            return [self[i] for i in idx]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid idx type: {type(idx).__name__}\")\n",
    "    \n",
    "    #############################\n",
    "    # Properties\n",
    "    #############################\n",
    "    @property\n",
    "    def features(self) -> list[Feature]: # Return [Feature(...), ...]\n",
    "        return self._features\n",
    "\n",
    "    @property\n",
    "    def feature_indices(self) -> list[tuple[int, int]]: # Return [(start, end), ...]\n",
    "        if not hasattr(self, \"_feature_indices\") or self._feature_indices is None or len(self._feature_indices) == 0:\n",
    "            self._transform_data()\n",
    "        return self._feature_indices\n",
    "    \n",
    "    @property\n",
    "    def features_and_indices(self) -> list[tuple[Feature, tuple[int, int]]]: # Return [(Feature(...), (start, end)), ...]\n",
    "        return list(zip(self.features, self.feature_indices))\n",
    "    \n",
    "    @property\n",
    "    def feature_name_indices(self) -> dict[str, tuple[int, int]]: # Return {feature_name: (feat_idx, start, end), ...}\n",
    "        if not hasattr(self, \"_feature_name_indices\") or self._feature_name_indices is None:\n",
    "            self._transform_data()\n",
    "        return self._feature_name_indices\n",
    "    \n",
    "    @property\n",
    "    def transformed_data(self) -> jax.Array:\n",
    "        if not hasattr(self, \"_transformed_data\") or self._transformed_data is None:\n",
    "            self._transform_data()\n",
    "        return self._transformed_data\n",
    "    \n",
    "    #############################\n",
    "    # Methods\n",
    "    #############################\n",
    "    def with_transformed_data(\n",
    "        self,\n",
    "        transformed_data: np.ndarray,\n",
    "        **kwargs        \n",
    "    ) -> FeaturesList:\n",
    "        \"\"\"Create a new feature with transformed data.\"\"\"\n",
    "        \n",
    "        return FeaturesList(\n",
    "            features=[feat.with_transformed_data(transformed_data[:, start:end], **kwargs) \n",
    "                      for feat, (start, end) in self.features_and_indices],\n",
    "        )\n",
    "    \n",
    "    def set_transformations(self, feature_names_to_transformation: dict[str, BaseTransformation]) -> FeaturesList:\n",
    "        \"\"\"Set the transformations for the features.\"\"\"\n",
    "        \n",
    "        if not isinstance(feature_names_to_transformation, dict):\n",
    "            raise ValueError(f\"Invalid feature_names_to_transformation type: \"\n",
    "                             f\"{type(feature_names_to_transformation).__name__}.\"\n",
    "                             f\"Should be dict[str, BaseTransformation]\")\n",
    "        \n",
    "        for feat, transformation in feature_names_to_transformation.items():\n",
    "            self[feat].set_transformation(transformation)\n",
    "        self._transformed_data = None # Reset transformed data\n",
    "        return self\n",
    "        \n",
    "    def _transform_data(self):\n",
    "        self._feature_indices = []\n",
    "        self._feature_name_indices = {}\n",
    "        self._transformed_data = []\n",
    "        start, end = 0, 0\n",
    "        for i, feat in enumerate(self.features):\n",
    "            transformed_data = feat.transformed_data\n",
    "            end += transformed_data.shape[-1]\n",
    "            self._feature_indices.append((start, end))\n",
    "            self._feature_name_indices[feat.name] = (i, start, end)\n",
    "            self._transformed_data.append(transformed_data)\n",
    "            start = end\n",
    "\n",
    "        self._transformed_data = jnp.concatenate(self._transformed_data, axis=-1)\n",
    "    \n",
    "    def transform(self, data: dict[str, jax.Array]):\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError(f\"Invalid data type: {type(data).__name__}, should be dict[str, jax.Array]\")\n",
    "\n",
    "        transformed_data = [None] * len(self.features)\n",
    "        for feat_name, val in data.items():\n",
    "            feat_idx, _, _ = self.feature_name_indices[feat_name]\n",
    "            feat = self.features[feat_idx]\n",
    "            transformed_data[feat_idx] = feat.transform(val)\n",
    "        return jnp.concatenate(transformed_data, axis=-1)\n",
    "\n",
    "    def inverse_transform(self, xs) -> dict[str, jax.Array]:\n",
    "        orignial_data = {}\n",
    "        for feat, (start, end) in self.features_and_indices:\n",
    "            orignial_data[feat.name] = feat.inverse_transform(xs[:, start:end])\n",
    "        return orignial_data\n",
    "\n",
    "    def apply_constraints(self, xs, cfs, hard: bool = False, rng_key=None, **kwargs):\n",
    "        return jnp.concatenate(\n",
    "            [feat.apply_constraints(xs[:, start:end], cfs[:, start:end], \n",
    "                                    hard=hard, rng_key=rng_key, **kwargs) for feat, (start, end) in self.features_and_indices], axis=-1)\n",
    "    \n",
    "    def compute_reg_loss(self, xs, cfs, hard: bool = False):\n",
    "        reg_loss = 0.\n",
    "        for feat, (start, end) in self.features_and_indices:\n",
    "            reg_loss += feat.compute_reg_loss(xs[:, start:end], cfs[:, start:end], hard)\n",
    "        return reg_loss\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'features': [feat.to_dict() for feat in self.features],\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dict(cls, d):\n",
    "        return cls(\n",
    "            features=[Feature.from_dict(feat) for feat in d['features']],\n",
    "        )\n",
    "    \n",
    "    def to_pandas(self, use_transformed: bool = False) -> pd.DataFrame:\n",
    "        if use_transformed:\n",
    "            # data = {feat.name: feat.transformed_data.reshape(-1) for feat in self.features}\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            data = {feat.name: feat.data.reshape(-1) for feat in self.features}\n",
    "        return pd.DataFrame(data=data)\n",
    "\n",
    "    def save(self, saved_dir):\n",
    "        os.makedirs(saved_dir, exist_ok=True)\n",
    "        save_pytree(self.to_dict(), saved_dir)\n",
    "        \n",
    "    @classmethod\n",
    "    def load_from_path(cls, saved_dir):\n",
    "        return cls.from_dict(load_pytree(saved_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../assets/adult/data/data.csv')\n",
    "cont_feats = ['age', 'hours_per_week']\n",
    "cat_feats = [\"workclass\", \"education\", \"marital_status\",\"occupation\", \"race\", \"gender\"]\n",
    "\n",
    "feats_list = FeaturesList([\n",
    "    Feature(name, df[name].to_numpy().reshape(-1, 1), 'minmax') for name in cont_feats\n",
    "] + [\n",
    "    Feature(name, df[name].to_numpy().reshape(-1, 1), 'ohe') for name in cat_feats\n",
    "])\n",
    "assert feats_list.transformed_data.shape == (32561, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test __get_item__\n",
    "assert np.allclose(\n",
    "    feats_list['age'].transformed_data,\n",
    "    feats_list.transformed_data[:, 0:1]\n",
    ")\n",
    "assert np.allclose(\n",
    "    FeaturesList(feats_list[['age', 'hours_per_week', 'workclass']]).transformed_data,\n",
    "    feats_list.transformed_data[:, :6]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with_transformed_data\n",
    "transformed_xs = feats_list.transformed_data\n",
    "indices = np.random.choice(len(transformed_xs), size=100)\n",
    "feats_list_1 = feats_list.with_transformed_data(transformed_xs[indices])\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    feats_list.to_pandas().iloc[indices].reset_index(drop=True),\n",
    "    feats_list_1.to_pandas(),\n",
    "    check_exact=False,\n",
    "    check_dtype=False,\n",
    "    check_index_type=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set_transformations(transformation, correct_shape):\n",
    "    T = transformation\n",
    "    feats_list_2 = deepcopy(feats_list)\n",
    "    feats_list_2.set_transformations({\n",
    "        feat: T for feat in cat_feats\n",
    "    })\n",
    "    assert feats_list_2.transformed_data.shape == correct_shape\n",
    "    name = T.name if isinstance(T, BaseTransformation) else T\n",
    "\n",
    "    for feat in feats_list_2:\n",
    "        if feat.name in cat_feats:  \n",
    "            assert feat.transformation.name == name\n",
    "            assert feat.is_categorical\n",
    "        else:\n",
    "            assert feat.transformation.name == 'minmax'                       \n",
    "            assert feat.is_categorical is False\n",
    "        assert feat.is_immutable is False\n",
    "\n",
    "    x = jax.random.uniform(jax.random.PRNGKey(0), shape=(100, correct_shape[-1]))\n",
    "    _ = feats_list_2.apply_constraints(feats_list_2.transformed_data[:100], x, hard=False)\n",
    "    _ = feats_list_2.apply_constraints(feats_list_2.transformed_data[:100], x, hard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_transformations('ordinal', (32561, 8))\n",
    "test_set_transformations('ohe', (32561, 29))\n",
    "test_set_transformations('gumbel', (32561, 29))\n",
    "# TODO: [bug] raise error when set_transformations is called with \n",
    "# SoftmaxTransformation() or GumbelSoftmaxTransformation(),\n",
    "# instead of \"ohe\" or \"gumbel\".\n",
    "test_set_transformations(SoftmaxTransformation(), (32561, 29))\n",
    "test_set_transformations(GumbelSoftmaxTransformation(), (32561, 29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test transform and inverse_transform\n",
    "# Convert df to dict[str, np.ndarray]\n",
    "df_dict = {k: np.array(v).reshape(-1, 1) for k, v in df.iloc[:, :-1].to_dict(orient='list').items()}\n",
    "# feats_list.transform(df_dict) should be the same as feats_list.transformed_data\n",
    "transformed_data = feats_list.transform(df_dict)\n",
    "assert np.equal(feats_list.transformed_data, transformed_data).all()\n",
    "# feats_list.inverse_transform(transformed_data) should be the same as df_dict\n",
    "inverse_transformed_data = feats_list.inverse_transform(transformed_data)\n",
    "pd.testing.assert_frame_equal(\n",
    "    pd.DataFrame.from_dict({k: v.reshape(-1) for k, v in inverse_transformed_data.items()}),\n",
    "    pd.DataFrame.from_dict({k: v.reshape(-1) for k, v in df_dict.items()}),\n",
    "    check_dtype=False, check_exact=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test apply_constraints and compute_reg_loss\n",
    "x = np.random.randn(10, 29)\n",
    "constraint_cfs = feats_list.apply_constraints(feats_list.transformed_data[:10, :], x, hard=False)\n",
    "assert constraint_cfs.shape == (10, 29)\n",
    "assert np.allclose(\n",
    "    constraint_cfs[:, 2:].sum(axis=-1),\n",
    "    np.ones((10,)) * 6\n",
    ")\n",
    "assert constraint_cfs[: :2].min() >= 0 and constraint_cfs[: :2].max() <= 1\n",
    "assert feats_list.apply_constraints(feats_list.transformed_data[:10, :], x, hard=True).shape == (10, 29)\n",
    "\n",
    "reg_loss = feats_list.compute_reg_loss(feats_list.transformed_data, x)\n",
    "assert jnp.ndim(reg_loss) == 0\n",
    "assert np.all(reg_loss > 0)\n",
    "assert np.allclose(feats_list.compute_reg_loss(x, constraint_cfs), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test `to_pandas`\n",
    "feats_pd = feats_list.to_pandas()\n",
    "pd.testing.assert_frame_equal(\n",
    "    feats_pd,\n",
    "    pd.DataFrame.from_dict({k: v.reshape(-1) for k, v in df_dict.items()}),\n",
    "    check_dtype=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test save and load\n",
    "feats_list.save('tmp/data_module/')\n",
    "feats_list_1 = FeaturesList.load_from_path('tmp/data_module/')\n",
    "# remove tmp folder\n",
    "shutil.rmtree('tmp/data_module/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_ohe = skp.OneHotEncoder(sparse_output=False)\n",
    "sk_minmax = skp.MinMaxScaler()\n",
    "\n",
    "# for feat in feats_list.features:\n",
    "for feat in feats_list:\n",
    "    if feat.name in cont_feats:\n",
    "        assert np.allclose(\n",
    "            sk_minmax.fit_transform(feat.data),\n",
    "            feat.transformed_data,\n",
    "        ), f\"Failed at {feat.name}. \"\n",
    "    else:\n",
    "        assert np.allclose(\n",
    "            sk_ohe.fit_transform(feat.data),\n",
    "            feat.transformed_data,\n",
    "        ), f\"Failed at {feat.name}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
