{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Define utility funtions for `relax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "import nbdev\n",
    "from fastcore.basics import AttrDict\n",
    "from nbdev.showdoc import BasicMarkdownRenderer\n",
    "from inspect import isclass\n",
    "from fastcore.test import *\n",
    "from jax.core import InconclusiveDimensionOperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_configs(\n",
    "    configs: dict | BaseParser,  # A configuration of the model/dataset.\n",
    "    config_cls: BaseParser,  # The desired configuration class.\n",
    ") -> BaseParser:\n",
    "    \"\"\"return a valid configuration object.\"\"\"\n",
    "\n",
    "    assert isclass(config_cls), f\"`config_cls` should be a class.\"\n",
    "    assert issubclass(config_cls, BaseParser), \\\n",
    "        f\"{config_cls} should be a subclass of `BaseParser`.\"\n",
    "    \n",
    "    if isinstance(configs, dict):\n",
    "        configs = config_cls(**configs)\n",
    "    if not isinstance(configs, config_cls):\n",
    "        raise TypeError(\n",
    "            f\"configs should be either a `dict` or an instance of {config_cls.__name__}.\")\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a configuration object (which inherent `BaseParser`) \n",
    "to manage training/model/data configurations.\n",
    "`validate_configs` ensures to return the designated configuration object.\n",
    "\n",
    "For example, we define a configuration object `LearningConfigs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningConfigs(BaseParser):\n",
    "    lr: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A configuration can be `LearningConfigs`, or the raw data in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = dict(lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`validate_configs` will return a designated configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = validate_configs(configs_dict, LearningConfigs)\n",
    "assert type(configs) == LearningConfigs\n",
    "assert configs.lr == configs_dict['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# TODO: add a test for this\n",
    "# from relax.module import PredictiveTrainingModuleConfigs\n",
    "# from relax.methods.counternet import CounterNetTrainingModuleConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# TODO: add a test for this\n",
    "# configs = {\n",
    "#     'lr': 0.1,\n",
    "#     'sizes': [10, 5],\n",
    "#     'lambda_1': 1.,\n",
    "#     'lambda_2': 1.,\n",
    "#     'lambda_3': 1.,\n",
    "# }\n",
    "# p_config = validate_configs(configs, PredictiveTrainingModuleConfigs)\n",
    "# cf_config = validate_configs(configs, CounterNetTrainingModuleConfigs)\n",
    "\n",
    "# assert isinstance(p_config, PredictiveTrainingModuleConfigs)\n",
    "# assert isinstance(cf_config, CounterNetTrainingModuleConfigs)\n",
    "\n",
    "# assert not isinstance(p_config, dict)\n",
    "# assert not isinstance(cf_config, dict)\n",
    "\n",
    "# p_config = validate_configs(p_config, PredictiveTrainingModuleConfigs)\n",
    "# cf_config = validate_configs(cf_config, CounterNetTrainingModuleConfigs)\n",
    "\n",
    "# assert isinstance(p_config, PredictiveTrainingModuleConfigs)\n",
    "# assert isinstance(cf_config, CounterNetTrainingModuleConfigs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _is_array(x):\n",
    "    return isinstance(x, np.ndarray) or isinstance(x, jnp.ndarray) or isinstance(x, list)\n",
    "\n",
    "def save_pytree(pytree, saved_dir):\n",
    "    \"\"\"Save a pytree to a directory.\"\"\"\n",
    "    with open(os.path.join(saved_dir, \"data.npy\"), \"wb\") as f:\n",
    "        for x in jax.tree_util.tree_leaves(pytree):\n",
    "            np.save(f, x)\n",
    "\n",
    "    tree_struct = jax.tree_util.tree_map(lambda t: _is_array(t), pytree)\n",
    "    with open(os.path.join(saved_dir, \"treedef.json\"), \"w\") as f:\n",
    "        json.dump(tree_struct, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pytree will be stored under a directory with two files: \n",
    "\n",
    "* `{saved_dir}/data.npy`: This file stores the flattened leaves.\n",
    "* `{saved_dir}/treedef.json`: This file stores the pytree structure and the information on whether the leave is an array or not. \n",
    "\n",
    "For example, a pytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytree = {\n",
    "    'a': np.random.randn(5, 1),\n",
    "    'b': 1,\n",
    "    'c': {\n",
    "        \n",
    "        'd': True,\n",
    "        'e': \"Hello\",\n",
    "        'f': np.array([\"a\", \"b\", \"c\"])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will be stored as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "data, pytreedef = jax.tree_util.tree_flatten(pytree)\n",
    "pytreedef = jax.tree_util.tree_map(lambda x: _is_array(x), pytree)\n",
    "print('data: ', data)\n",
    "print('treedef: ', pytreedef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_pytree(saved_dir):\n",
    "    \"\"\"Load a pytree from a saved directory.\"\"\"\n",
    "    with open(os.path.join(saved_dir, \"treedef.json\"), \"r\") as f:\n",
    "        tree_struct = json.load(f)\n",
    "\n",
    "    leaves, treedef = jax.tree_util.tree_flatten(tree_struct)\n",
    "    with open(os.path.join(saved_dir, \"data.npy\"), \"rb\") as f:\n",
    "        flat_state = [\n",
    "            np.load(f, allow_pickle=True) if is_arr else np.load(f, allow_pickle=True).item()\n",
    "            for is_arr in leaves\n",
    "        ]\n",
    "    return jax.tree_util.tree_unflatten(treedef, flat_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a dictionary to disk\n",
    "pytree = {\n",
    "    'a': np.random.randn(100, 1),\n",
    "    'b': 1,\n",
    "    'c': {\n",
    "        'd': True,\n",
    "        'e': \"Hello\",\n",
    "        'f': np.array([\"a\", \"b\", \"c\"])\n",
    "    }\n",
    "}\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "save_pytree(pytree, 'tmp')\n",
    "pytree_loaded = load_pytree('tmp')\n",
    "assert np.allclose(pytree['a'], pytree_loaded['a'])\n",
    "assert pytree['a'].dtype == pytree_loaded['a'].dtype\n",
    "assert pytree['b'] == pytree_loaded['b']\n",
    "assert pytree['c']['d'] == pytree_loaded['c']['d']\n",
    "assert pytree['c']['e'] == pytree_loaded['c']['e']\n",
    "assert np.all(pytree['c']['f'] == pytree_loaded['c']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a list to disk\n",
    "pytree = [\n",
    "    np.random.randn(100, 1),\n",
    "    {'a': 1, 'b': np.array([1, 2, 3])},\n",
    "    1,\n",
    "    [1, 2, 3],\n",
    "    \"good\"\n",
    "]\n",
    "save_pytree(pytree, 'tmp')\n",
    "pytree_loaded = load_pytree('tmp')\n",
    "\n",
    "assert np.allclose(pytree[0], pytree_loaded[0])\n",
    "assert pytree[0].dtype == pytree_loaded[0].dtype\n",
    "assert pytree[1]['a'] == pytree_loaded[1]['a']\n",
    "assert np.all(pytree[1]['b'] == pytree_loaded[1]['b'])\n",
    "assert pytree[2] == pytree_loaded[2]\n",
    "assert pytree[3] == pytree_loaded[3]\n",
    "assert isinstance(pytree_loaded[3], list)\n",
    "assert pytree[4] == pytree_loaded[4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _reshape_x(x: Array):\n",
    "    x_size = x.shape\n",
    "    if len(x_size) > 1 and x_size[0] != 1:\n",
    "        raise ValueError(\n",
    "            f\"\"\"Invalid Input Shape: Require `x.shape` = (1, k) or (k, ),\n",
    "but got `x.shape` = {x.shape}. This method expects a single input instance.\"\"\"\n",
    "        )\n",
    "    if len(x_size) == 1:\n",
    "        x = x.reshape(1, -1)\n",
    "    return x, x_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def auto_reshaping(\n",
    "    reshape_argname: str, # The name of the argument to be reshaped.\n",
    "    reshape_output: bool = True, # Whether to reshape the output. Useful to set `False` when returning multiple cfs.\n",
    "):\n",
    "    \"\"\"\n",
    "    Decorator to automatically reshape function's input into (1, k), \n",
    "    and out to input's shape.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            kwargs = inspect.getcallargs(func, *args, **kwargs)\n",
    "            if reshape_argname in kwargs:\n",
    "                reshaped_x, x_shape = _reshape_x(kwargs[reshape_argname])\n",
    "                kwargs[reshape_argname] = reshaped_x\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid argument name: `{reshape_argname}` is not a valid argument name.\")\n",
    "            # Call the function.\n",
    "            cf = func(**kwargs)\n",
    "            if not isinstance(cf, Array): \n",
    "                raise ValueError(\n",
    "                    f\"Invalid return type: must be a `jax.Array`, but got `{type(cf).__name__}`.\")\n",
    "            if reshape_output:\n",
    "                try: \n",
    "                    cf = cf.reshape(x_shape)\n",
    "                except (InconclusiveDimensionOperation, TypeError) as e:\n",
    "                    raise ValueError(\n",
    "                        f\"Invalid return shape: Require `cf.shape` = {cf.shape} \"\n",
    "                        f\"is not compatible with `x.shape` = {x_shape}.\")\n",
    "            return cf\n",
    "\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decorator ensures that the specified input argument and output \n",
    "of a function are in the same shape. \n",
    "This is particularly useful when using `jax.vamp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@auto_reshaping('x')\n",
    "def f_vmap(x): return x * jnp.ones((10,))\n",
    "assert vmap(f_vmap)(jnp.ones((10, 10))).shape == (10, 10)\n",
    "\n",
    "@auto_reshaping('x', reshape_output=False)\n",
    "def f_vmap(x): return x * jnp.ones((10,))\n",
    "assert vmap(f_vmap)(jnp.ones((10, 10))).shape == (10, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "@auto_reshaping('x')\n",
    "def f_1(x):\n",
    "    assert x.shape[0] == 1\n",
    "    return x\n",
    "\n",
    "assert f_1(jnp.ones(10)).shape == (10,)\n",
    "assert f_1(jnp.ones((1, 10))).shape == (1, 10)\n",
    "\n",
    "@auto_reshaping('x')\n",
    "@jit\n",
    "def f_2(y, x):\n",
    "    assert x.shape[0] == 1\n",
    "    return x\n",
    "\n",
    "assert f_2(None, jnp.ones(10)).shape == (10,)\n",
    "assert f_2(None, jnp.ones((1, 10))).shape == (1, 10)\n",
    "\n",
    "@auto_reshaping('x')\n",
    "def f_3(x, y): return x\n",
    "test_fail(f_3, args=(jnp.ones((10, 10)), None), \n",
    "          contains='Invalid Input Shape: Require `x.shape` = (1, k)')\n",
    "\n",
    "@auto_reshaping('x')\n",
    "def f_4(x, y): return jnp.arange(3)\n",
    "test_fail(f_4, args=(jnp.ones((10, )), None), \n",
    "          contains='Invalid return shape: Require `cf.shape`')\n",
    "\n",
    "@auto_reshaping('x')\n",
    "def f_5(x, y): return jnp.array([1, 2, 3]), jnp.array([1, 2, 3])\n",
    "test_fail(f_5, args=(jnp.ones((10, )), None), \n",
    "          contains='Invalid return type: must be a `jax.Array`, but got `tuple`.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def grad_update(\n",
    "    grads, # A pytree of gradients.\n",
    "    params, # A pytree of parameters.\n",
    "    opt_state: optax.OptState,\n",
    "    opt: optax.GradientTransformation,\n",
    "): # Return (upt_params, upt_opt_state)\n",
    "    updates, opt_state = opt.update(grads, opt_state, params)\n",
    "    upt_params = optax.apply_updates(params, updates)\n",
    "    return upt_params, opt_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_json(f_name: str) -> Dict[str, Any]:  # file name\n",
    "    with open(f_name) as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@dataclass\n",
    "class Config:\n",
    "    rng_reserve_size: int\n",
    "    global_seed: int\n",
    "\n",
    "    @classmethod\n",
    "    def default(cls) -> Config:\n",
    "        return cls(rng_reserve_size=1, global_seed=42)\n",
    "\n",
    "main_config = Config.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_config() -> Config: \n",
    "    return main_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def set_config(\n",
    "    *,\n",
    "    rng_reserve_size: int = None, # The number of random number generators to reserve.\n",
    "    global_seed: int = None, # The global seed for random number generators.\n",
    "    **kwargs\n",
    ") -> None:\n",
    "    \"\"\"Sets the global configurations.\"\"\"\n",
    "\n",
    "    def set_val(\n",
    "        arg_name: str, # The name of the argument.\n",
    "        arg_value: int, # The value of the argument.\n",
    "        arg_min: int # The minimum value of the argument.\n",
    "    ) -> None:\n",
    "        \"\"\"Checks the validity of the argument and sets the value.\"\"\"\n",
    "        \n",
    "        if arg_value is None or not hasattr(main_config, arg_name):\n",
    "            return\n",
    "        \n",
    "        if not isinstance(arg_value, int):\n",
    "            raise TypeError(f\"`{arg_name}` must be an integer, but got {type(arg_value).__name__}.\")\n",
    "        if arg_value < arg_min:\n",
    "            raise ValueError(f\"`{arg_name}` must be non-negative, but got {arg_value}.\")\n",
    "        setattr(main_config, arg_name, arg_value)\n",
    "\n",
    "    set_val('rng_reserve_size', rng_reserve_size, 1)\n",
    "    set_val('global_seed', global_seed, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Test cases\n",
    "set_config()\n",
    "assert get_config().rng_reserve_size == 1 and get_config().global_seed == 42\n",
    "set_config(rng_reserve_size=100)\n",
    "assert get_config().rng_reserve_size == 100\n",
    "set_config(global_seed=1234)\n",
    "assert get_config().global_seed == 1234\n",
    "set_config(rng_reserve_size=2, global_seed=234)\n",
    "assert get_config().rng_reserve_size == 2 and get_config().global_seed == 234\n",
    "set_config()\n",
    "assert get_config().rng_reserve_size == 2 and get_config().global_seed == 234\n",
    "set_config(invalid_key = 80)\n",
    "assert get_config().rng_reserve_size == 2 and get_config().global_seed == 234"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
