{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Define utility funtions for `relax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using JAX backend.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "import nbdev\n",
    "from fastcore.basics import AttrDict\n",
    "from nbdev.showdoc import BasicMarkdownRenderer\n",
    "from inspect import isclass\n",
    "from fastcore.test import *\n",
    "from jax.core import InconclusiveDimensionOperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_configs(\n",
    "    configs: dict | BaseParser,  # A configuration of the model/dataset.\n",
    "    config_cls: BaseParser,  # The desired configuration class.\n",
    ") -> BaseParser:\n",
    "    \"\"\"return a valid configuration object.\"\"\"\n",
    "\n",
    "    assert isclass(config_cls), f\"`config_cls` should be a class.\"\n",
    "    assert issubclass(config_cls, BaseParser), \\\n",
    "        f\"{config_cls} should be a subclass of `BaseParser`.\"\n",
    "    \n",
    "    if isinstance(configs, dict):\n",
    "        configs = config_cls(**configs)\n",
    "    if not isinstance(configs, config_cls):\n",
    "        raise TypeError(\n",
    "            f\"configs should be either a `dict` or an instance of {config_cls.__name__}.\")\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a configuration object (which inherent `BaseParser`) \n",
    "to manage training/model/data configurations.\n",
    "`validate_configs` ensures to return the designated configuration object.\n",
    "\n",
    "For example, we define a configuration object `LearningConfigs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningConfigs(BaseParser):\n",
    "    lr: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A configuration can be `LearningConfigs`, or the raw data in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = dict(lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`validate_configs` will return a designated configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = validate_configs(configs_dict, LearningConfigs)\n",
    "assert type(configs) == LearningConfigs\n",
    "assert configs.lr == configs_dict['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# TODO: add a test for this\n",
    "# from relax.module import PredictiveTrainingModuleConfigs\n",
    "# from relax.methods.counternet import CounterNetTrainingModuleConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# TODO: add a test for this\n",
    "# configs = {\n",
    "#     'lr': 0.1,\n",
    "#     'sizes': [10, 5],\n",
    "#     'lambda_1': 1.,\n",
    "#     'lambda_2': 1.,\n",
    "#     'lambda_3': 1.,\n",
    "# }\n",
    "# p_config = validate_configs(configs, PredictiveTrainingModuleConfigs)\n",
    "# cf_config = validate_configs(configs, CounterNetTrainingModuleConfigs)\n",
    "\n",
    "# assert isinstance(p_config, PredictiveTrainingModuleConfigs)\n",
    "# assert isinstance(cf_config, CounterNetTrainingModuleConfigs)\n",
    "\n",
    "# assert not isinstance(p_config, dict)\n",
    "# assert not isinstance(cf_config, dict)\n",
    "\n",
    "# p_config = validate_configs(p_config, PredictiveTrainingModuleConfigs)\n",
    "# cf_config = validate_configs(cf_config, CounterNetTrainingModuleConfigs)\n",
    "\n",
    "# assert isinstance(p_config, PredictiveTrainingModuleConfigs)\n",
    "# assert isinstance(cf_config, CounterNetTrainingModuleConfigs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _reshape_x(x: Array):\n",
    "    x_size = x.shape\n",
    "    if len(x_size) > 1 and x_size[0] != 1:\n",
    "        raise ValueError(\n",
    "            f\"\"\"Invalid Input Shape: Require `x.shape` = (1, k) or (k, ),\n",
    "but got `x.shape` = {x.shape}. This method expects a single input instance.\"\"\"\n",
    "        )\n",
    "    if len(x_size) == 1:\n",
    "        x = x.reshape(1, -1)\n",
    "    return x, x_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def auto_reshaping(reshape_argname: str):\n",
    "    \"\"\"\n",
    "    Decorator to automatically reshape function's input into (1, k), \n",
    "    and out to input's shape.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            kwargs = inspect.getcallargs(func, *args, **kwargs)\n",
    "            if reshape_argname in kwargs:\n",
    "                reshaped_x, x_shape = _reshape_x(kwargs[reshape_argname])\n",
    "                kwargs[reshape_argname] = reshaped_x\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid argument name: `{reshape_argname}` is not a valid argument name.\")\n",
    "            cf = func(**kwargs)\n",
    "            if not isinstance(cf, Array): \n",
    "                raise ValueError(\n",
    "                    f\"Invalid return type: must be a `jax.Array`, but got `{type(cf).__name__}`.\")\n",
    "            try: \n",
    "                cf = cf.reshape(x_shape)\n",
    "            except (InconclusiveDimensionOperation, TypeError) as e:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid return shape: Require `cf.shape` = {cf.shape} \"\n",
    "                    f\"is not compatible with `x.shape` = {x_shape}.\")\n",
    "            return cf\n",
    "\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decorator ensures that the specified input argument and output \n",
    "of a function are in the same shape. \n",
    "This is particularly useful when using `jax.vamp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@auto_reshaping('x')\n",
    "def f_vmap(x): return x * jnp.ones((10,))\n",
    "assert vmap(f_vmap)(jnp.ones((10, 10))).shape == (10, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "@auto_reshaping('x')\n",
    "def f_1(x):\n",
    "    assert x.shape[0] == 1\n",
    "    return x\n",
    "\n",
    "assert f_1(jnp.ones(10)).shape == (10,)\n",
    "assert f_1(jnp.ones((1, 10))).shape == (1, 10)\n",
    "\n",
    "@auto_reshaping('x')\n",
    "@jit\n",
    "def f_2(y, x):\n",
    "    assert x.shape[0] == 1\n",
    "    return x\n",
    "\n",
    "assert f_2(None, jnp.ones(10)).shape == (10,)\n",
    "assert f_2(None, jnp.ones((1, 10))).shape == (1, 10)\n",
    "\n",
    "@auto_reshaping('x')\n",
    "def f_3(x, y): return x\n",
    "test_fail(f_3, args=(jnp.ones((10, 10)), None), \n",
    "          contains='Invalid Input Shape: Require `x.shape` = (1, k)')\n",
    "\n",
    "@auto_reshaping('x')\n",
    "def f_4(x, y): return jnp.arange(3)\n",
    "test_fail(f_4, args=(jnp.ones((10, )), None), \n",
    "          contains='Invalid return shape: Require `cf.shape`')\n",
    "\n",
    "@auto_reshaping('x')\n",
    "def f_5(x, y): return jnp.array([1, 2, 3]), jnp.array([1, 2, 3])\n",
    "test_fail(f_5, args=(jnp.ones((10, )), None), \n",
    "          contains='Invalid return type: must be a `jax.Array`, but got `tuple`.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def grad_update(\n",
    "    grads, # A pytree of gradients.\n",
    "    params, # A pytree of parameters.\n",
    "    opt_state: optax.OptState,\n",
    "    opt: optax.GradientTransformation,\n",
    "): # Return (upt_params, upt_opt_state)\n",
    "    updates, opt_state = opt.update(grads, opt_state, params)\n",
    "    upt_params = optax.apply_updates(params, updates)\n",
    "    return upt_params, opt_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_json(f_name: str) -> Dict[str, Any]:  # file name\n",
    "    with open(f_name) as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@dataclass\n",
    "class Config:\n",
    "    rng_reserve_size: int\n",
    "    global_seed: int\n",
    "\n",
    "    @classmethod\n",
    "    def default(cls) -> Config:\n",
    "        return cls(rng_reserve_size=1, global_seed=42)\n",
    "\n",
    "main_config = Config.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_config() -> Config: \n",
    "    return main_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
