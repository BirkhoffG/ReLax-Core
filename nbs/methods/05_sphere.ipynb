{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Growing Sphere\n",
    "\n",
    "Note: This method only works with one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp methods.sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "from nbdev import show_doc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "from relax.methods.base import CFModule\n",
    "from relax.utils import auto_reshaping, grad_update, validate_configs\n",
    "from relax.data_utils import Feature, FeaturesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from relax.data_module import load_data\n",
    "from relax.ml_model import load_ml_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@partial(jit, static_argnums=(2, 5))\n",
    "def hyper_sphere_coordindates(\n",
    "    rng_key: jrand.PRNGKey, # Random number generator key\n",
    "    x: Array, # Input instance with only continuous features. Shape: (1, n_features)\n",
    "    n_samples: int, # Number of samples\n",
    "    high: float, # Upper bound\n",
    "    low: float, # Lower bound\n",
    "    p_norm: int = 2 # Norm\n",
    "):\n",
    "    # Adapted from \n",
    "    # https://github.com/carla-recourse/CARLA/blob/24db00aa8616eb2faedea0d6edf6e307cee9d192/carla/recourse_methods/catalog/growing_spheres/library/gs_counterfactuals.py#L8\n",
    "    key_1, key_2 = jrand.split(rng_key)\n",
    "    delta = jrand.normal(key_1, shape=(n_samples, x.shape[-1]))\n",
    "    dist = jrand.uniform(key_2, shape=(n_samples,)) * (high - low) + low\n",
    "    norm_p = jnp.linalg.norm(delta, ord=p_norm, axis=1)\n",
    "    d_norm = jnp.divide(dist, norm_p).reshape(-1, 1)  # rescale/normalize factor\n",
    "    delta = jnp.multiply(delta, d_norm)\n",
    "    candidates = x + delta\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@partial(jit, static_argnums=(1, 2))\n",
    "def sample_categorical(rng_key: jrand.PRNGKey, col_size: int, n_samples: int):\n",
    "    rng_key, _ = jrand.split(rng_key)\n",
    "    prob = jnp.ones(col_size) / col_size\n",
    "    cat_sample = jrand.categorical(rng_key, prob, shape=(n_samples, 1))\n",
    "    return cat_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def default_perturb_function(\n",
    "    rng_key: jrand.PRNGKey,\n",
    "    x: np.ndarray, # Shape: (1, k)\n",
    "    n_samples: int,\n",
    "    high: float,\n",
    "    low: float,\n",
    "    p_norm: int\n",
    "):\n",
    "    return hyper_sphere_coordindates(\n",
    "        rng_key, x, n_samples, high, low, p_norm\n",
    "    )\n",
    "\n",
    "def perturb_function_with_features(\n",
    "    rng_key: jrand.PRNGKey,\n",
    "    x: np.ndarray, # Shape: (1, k)\n",
    "    n_samples: int,\n",
    "    high, \n",
    "    low,\n",
    "    p_norm,\n",
    "    feats: FeaturesList,\n",
    "):\n",
    "    def perturb_feature(rng_key, x, feat):\n",
    "        if feat.is_categorical:\n",
    "            return feat.transform(\n",
    "                sample_categorical(\n",
    "                    rng_key, feat.transformation.num_categories, n_samples\n",
    "                ) #<== sampled labels\n",
    "            ) #<== transformed labels\n",
    "        else: \n",
    "            return hyper_sphere_coordindates(\n",
    "                rng_key, x, n_samples, high, low, p_norm\n",
    "            ) #<== transformed continuous features\n",
    "        \n",
    "    rng_keys = jrand.split(rng_key, len(feats))\n",
    "    perturbed = jnp.repeat(x, n_samples, axis=0)\n",
    "    for rng_key, (start, end), feat in zip(rng_keys, feats.feature_indices, feats):\n",
    "        _perturbed_feat = perturb_feature(rng_keys[0], x[:, start: end], feat)\n",
    "        perturbed = perturbed.at[:, start: end].set(_perturbed_feat)\n",
    "    return perturbed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data('adult')\n",
    "x = dm.xs[:1]\n",
    "assert x.ndim == 2\n",
    "assert perturb_function_with_features(\n",
    "    jrand.PRNGKey(0), x, 100, 1, 0, 2, feats=dm.features\n",
    ").shape == (100, 29)\n",
    "assert default_perturb_function(\n",
    "    jrand.PRNGKey(0), x, 100, 1, 0, 2,\n",
    ").shape == (100, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _growing_spheres(\n",
    "    rng_key: jrand.PRNGKey, # Random number generator key\n",
    "    y_target: Array, # Target label\n",
    "    x: Array, # Input instance. Shape: (n_features)\n",
    "    pred_fn: Callable, # Prediction function\n",
    "    n_steps: int, # Number of steps\n",
    "    n_samples: int,  # Number of samples to sample\n",
    "    step_size: float, # Step size\n",
    "    p_norm: int, # Norm\n",
    "    perturb_fn: Callable, # Perturbation function\n",
    "    apply_constraints_fn: Callable # Apply immutable constraints\n",
    "): \n",
    "    @jit\n",
    "    def dist_fn(x, cf):\n",
    "        if p_norm == 1:\n",
    "            return jnp.abs(cf - x).sum(axis=1)\n",
    "        elif p_norm == 2:\n",
    "            return jnp.linalg.norm(cf - x, ord=2, axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Only p_norm = 1 or 2 is supported\")\n",
    "    \n",
    "    @loop_tqdm(n_steps)\n",
    "    def step(i, state):\n",
    "        candidate_cf, count, rng_key = state\n",
    "        rng_key, subkey_1, subkey_2 = jrand.split(rng_key, num=3)\n",
    "        low, high = step_size * count, step_size * (count + 1)\n",
    "        # Sample around x\n",
    "        candidates = perturb_fn(rng_key, x, n_samples, high=high, low=low, p_norm=p_norm)\n",
    "        \n",
    "        # Apply immutable constraints\n",
    "        candidates = apply_constraints_fn(x, candidates, hard=True)\n",
    "        assert candidates.shape[1] == x.shape[1], f\"candidates.shape = {candidates.shape}, x.shape = {x.shape}\"\n",
    "\n",
    "        # Calculate distance\n",
    "        dist = dist_fn(x, candidates)\n",
    "\n",
    "        # Calculate counterfactual labels\n",
    "        candidate_preds = pred_fn(candidates).argmax(axis=1)\n",
    "        indices = jnp.where(candidate_preds == y_target, 1, 0).astype(bool)\n",
    "\n",
    "        candidates = jnp.where(indices.reshape(-1, 1), \n",
    "                               candidates, jnp.ones_like(candidates) * jnp.inf)\n",
    "        dist = jnp.where(indices.reshape(-1, 1), dist, jnp.ones_like(dist) * jnp.inf)\n",
    "\n",
    "        closest_idx = dist.argmin()\n",
    "        candidate_cf_update = candidates[closest_idx].reshape(1, -1)\n",
    "\n",
    "        candidate_cf = jnp.where(\n",
    "            dist[closest_idx].mean() < dist_fn(x, candidate_cf).mean(),\n",
    "            candidate_cf_update, \n",
    "            candidate_cf\n",
    "        )\n",
    "        return candidate_cf, count + 1, rng_key\n",
    "    \n",
    "    y_target = y_target.reshape(1, -1).argmax(axis=1)\n",
    "    candidate_cf = jnp.ones_like(x) * jnp.inf\n",
    "    count = 0\n",
    "    state = (candidate_cf, count, rng_key)\n",
    "    candidate_cf, _, _ = lax.fori_loop(0, n_steps, step, state)\n",
    "    # if `inf` is found, return the original input\n",
    "    candidate_cf = jnp.where(jnp.isinf(candidate_cf), x, candidate_cf)\n",
    "    return candidate_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GSConfig(BaseParser):\n",
    "    n_steps: int = 100\n",
    "    n_samples: int = 1000\n",
    "    step_size: float = 0.05\n",
    "    p_norm: int = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GrowingSphere(CFModule):\n",
    "    def __init__(self, config: dict | GSConfig = None, *, name: str = None, perturb_fn = None):\n",
    "        if config is None:\n",
    "             config = GSConfig()\n",
    "        config = validate_configs(config, GSConfig)\n",
    "        name = \"GrowingSphere\" if name is None else name\n",
    "        self.perturb_fn = perturb_fn\n",
    "        super().__init__(config, name=name)\n",
    "\n",
    "    def before_generate_cf(self, *args, **kwargs):\n",
    "        if self.perturb_fn is None:\n",
    "            if hasattr(self, 'data_module'):\n",
    "                self.perturb_fn = ft.partial(\n",
    "                    perturb_function_with_features, feats=self.data_module.features\n",
    "                )\n",
    "            else:\n",
    "                self.perturb_fn = default_perturb_function\n",
    "        \n",
    "    @auto_reshaping('x')\n",
    "    def generate_cf(\n",
    "        self,\n",
    "        x: Array,  # `x` shape: (k,), where `k` is the number of features\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "        y_target: Array = None,\n",
    "        rng_key: jnp.ndarray = None,\n",
    "        **kwargs,\n",
    "    ) -> jnp.DeviceArray:\n",
    "        # TODO: Currently assumes binary classification.\n",
    "        if y_target is None:\n",
    "            y_target = 1 - pred_fn(x)\n",
    "        else:\n",
    "            y_target = jnp.array(y_target, copy=True)\n",
    "        if rng_key is None:\n",
    "            raise ValueError(\"`rng_key` must be provided, but got `None`.\")\n",
    "        \n",
    "        return _growing_spheres(\n",
    "            rng_key=rng_key,\n",
    "            x=x,\n",
    "            y_target=y_target,\n",
    "            pred_fn=pred_fn,\n",
    "            n_steps=self.config.n_steps,\n",
    "            n_samples=self.config.n_samples,\n",
    "            step_size=self.config.step_size,\n",
    "            p_norm=self.config.p_norm,\n",
    "            perturb_fn=self.perturb_fn,\n",
    "            apply_constraints_fn=self.apply_constraints_fn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data('dummy')\n",
    "model = load_ml_module('dummy')\n",
    "xs_train, ys_train = dm['train']\n",
    "xs_test, ys_test = dm['test']\n",
    "x_shape = xs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GrowingSphere()\n",
    "gs.set_data_module(dm)\n",
    "gs.init_fns(apply_constraints_fn=dm.apply_constraints)\n",
    "gs.before_generate_cf()\n",
    "\n",
    "cf = gs.generate_cf(xs_test[0], pred_fn=model.pred_fn, rng_key=jax.random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "partial_gen = partial(gs.generate_cf, pred_fn=model.pred_fn)\n",
    "cfs = jax.vmap(jit(partial_gen))(xs_test, rng_key=jrand.split(jrand.PRNGKey(0), len(xs_test)))\n",
    "\n",
    "assert cfs.shape == (x_shape[0], x_shape[1])\n",
    "\n",
    "print(\"Validity: \", keras.metrics.binary_accuracy(\n",
    "    (1 - model.pred_fn(xs_test)).round(),\n",
    "    model.pred_fn(cfs[:, :])\n",
    ").mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
