{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diverse CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp methods.dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "from relax.methods.base import CFModule\n",
    "from relax.base import BaseConfig\n",
    "from relax.utils import auto_reshaping, grad_update, validate_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from relax.ml_model import MLModule\n",
    "from relax.data_module import load_data\n",
    "from relax.ml_model import load_ml_module\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@jit\n",
    "def dpp_style_vmap(cfs: Array):\n",
    "    def dpp_fn(cf_1, cf_2):\n",
    "        return 1 / (1 + jnp.linalg.norm(cf_1 - cf_2, ord=1))\n",
    "    \n",
    "    det_entries = vmap(vmap(dpp_fn, in_axes=(None, 0)), in_axes=(0, None))(cfs, cfs)\n",
    "    det_entries += jnp.eye(cfs.shape[0]) * 1e-8\n",
    "    assert det_entries.shape == (cfs.shape[0], cfs.shape[0])\n",
    "    return jnp.linalg.det(det_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the original dice implementation\n",
    "# https://github.com/interpretml/DiCE/blob/a772c8d4fcd88d1cab7f2e02b0bcc045dc0e2eab/dice_ml/explainer_interfaces/dice_pytorch.py#L222-L227\n",
    "def dpp_style_torch(cfs: torch.Tensor):\n",
    "    compute_dist = lambda x, y: torch.abs(x-y).sum()\n",
    "\n",
    "    total_CFs = len(cfs)\n",
    "    det_entries = torch.ones((total_CFs, total_CFs))\n",
    "    for i in range(total_CFs):\n",
    "        for j in range(total_CFs):\n",
    "            det_entries[(i,j)] = 1.0/(1.0 + compute_dist(cfs[i], cfs[j]))\n",
    "            if i == j:\n",
    "                det_entries[(i,j)] += 1e-8\n",
    "    return torch.det(det_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jax2torch(x: Array):\n",
    "    return torch.from_numpy(x.__array__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = jrand.normal(jrand.PRNGKey(0), (100, 100))\n",
    "cfs_tensor = jax2torch(cfs)\n",
    "assert np.allclose(\n",
    "    dpp_style_torch(cfs_tensor).numpy(),\n",
    "    dpp_style_vmap(cfs)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our jax-based implementation is ~500X faster than DiCE's pytorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 ms ± 4.81 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch_res = dpp_style_torch(cfs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501 µs ± 17.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "jax_res = dpp_style_vmap(cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _diverse_cf(\n",
    "    x: jnp.DeviceArray,  # `x` shape: (k,), where `k` is the number of features\n",
    "    y_target: Array, # `y_target` shape: (1,)\n",
    "    pred_fn: Callable[[Array], Array],  # y = pred_fn(x)\n",
    "    n_cfs: int,\n",
    "    n_steps: int,\n",
    "    lr: float,  # learning rate for each `cf` optimization step\n",
    "    lambdas: Tuple[float, float, float, float], # (lambda_1, lambda_2, lambda_3, lambda_4)\n",
    "    key: jrand.PRNGKey,\n",
    "    validity_fn: Callable,\n",
    "    cost_fn: Callable,\n",
    "    apply_constraints_fn: Callable,\n",
    "    compute_reg_loss_fn: Callable,\n",
    ") -> Array:  # return `cf` shape: (k,)\n",
    "    \"\"\"Diverse Counterfactuals (Dice) algorithm.\"\"\"\n",
    "\n",
    "    def loss_fn(\n",
    "        cfs: Array, # shape: (n_cfs, k)\n",
    "        x: Array, # shape: (1, k)\n",
    "        pred_fn: Callable[[Array], Array], # y = pred_fn(x)\n",
    "        y_target: Array,\n",
    "    ):\n",
    "        cf_y_pred = pred_fn(cfs)\n",
    "        loss_1 = validity_fn(y_target, cf_y_pred).mean()\n",
    "        loss_2 = cost_fn(x, cfs).mean()\n",
    "        loss_3 = - dpp_style_vmap(cfs).mean()\n",
    "        loss_4 = compute_reg_loss_fn(x, cfs)\n",
    "        return (\n",
    "            lambda_1 * loss_1 + \n",
    "            lambda_2 * loss_2 + \n",
    "            lambda_3 * loss_3 + \n",
    "            lambda_4 * loss_4\n",
    "        )\n",
    "    \n",
    "    @loop_tqdm(n_steps)\n",
    "    def gen_cf_step(i, states: Tuple[Array, optax.OptState]):\n",
    "        cf, opt_state = states\n",
    "        grads = jax.grad(loss_fn)(cf, x, pred_fn, y_target)\n",
    "        cf_updates, opt_state = grad_update(grads, cf, opt_state, opt)\n",
    "        return cf, opt_state\n",
    "    \n",
    "    lambda_1, lambda_2, lambda_3, lambda_4 = lambdas\n",
    "    key, subkey = jrand.split(key)\n",
    "    cfs = jrand.normal(key, (n_cfs, x.shape[-1]))\n",
    "    opt = optax.adam(lr)\n",
    "    opt_state = opt.init(cfs)\n",
    "    \n",
    "    cfs, opt_state = lax.fori_loop(0, n_steps, gen_cf_step, (cfs, opt_state))\n",
    "    # TODO: support return multiple cfs\n",
    "    cfs = apply_constraints_fn(x, cfs[:1, :], hard=True)\n",
    "    return cfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiverseCFConfig(BaseConfig):\n",
    "    n_cfs: int = 5\n",
    "    n_steps: int = 1000\n",
    "    lr: float = 0.001\n",
    "    lambda_1: float = 1.0\n",
    "    lambda_2: float = 0.1\n",
    "    lambda_3: float = 1.0\n",
    "    lambda_4: float = 0.1\n",
    "    validity_fn: str = 'KLDivergence'\n",
    "    cost_fn: str = 'MeanSquaredError'\n",
    "    seed: int = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiverseCF(CFModule):\n",
    "\n",
    "    def __init__(self, config: dict | DiverseCF = None, *, name: str = None):\n",
    "        if config is None:\n",
    "             config = DiverseCFConfig()\n",
    "        config = validate_configs(config, DiverseCFConfig)\n",
    "        name = \"DiverseCF\" if name is None else name\n",
    "        super().__init__(config, name=name)\n",
    "\n",
    "    @auto_reshaping('x')\n",
    "    def generate_cf(\n",
    "        self,\n",
    "        x: Array,  # `x` shape: (k,), where `k` is the number of features\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "        y_target: Array = None,\n",
    "        rng_key: jnp.ndarray = None,\n",
    "        **kwargs,\n",
    "    ) -> jnp.DeviceArray:\n",
    "        # TODO: Currently assumes binary classification.\n",
    "        if y_target is None:\n",
    "            y_target = 1 - pred_fn(x)\n",
    "        else:\n",
    "            y_target = jnp.array(y_target, copy=True)\n",
    "        if rng_key is None:\n",
    "            rng_key = jax.random.PRNGKey(self.config.seed)\n",
    "        \n",
    "        return _diverse_cf(\n",
    "            x=x,  # `x` shape: (k,), where `k` is the number of features\n",
    "            y_target=y_target,  # `y_target` shape: (1,)\n",
    "            pred_fn=pred_fn,  # y = pred_fn(x)\n",
    "            n_cfs=self.config.n_cfs,\n",
    "            n_steps=self.config.n_steps,\n",
    "            lr=self.config.lr,  # learning rate for each `cf` optimization step\n",
    "            lambdas=(\n",
    "                self.config.lambda_1, self.config.lambda_2, \n",
    "                self.config.lambda_3, self.config.lambda_4\n",
    "            ),\n",
    "            key=rng_key,\n",
    "            validity_fn=keras.losses.get({'class_name': self.config.validity_fn, 'config': {'reduction': None}}),\n",
    "            cost_fn=keras.losses.get({'class_name': self.config.cost_fn, 'config': {'reduction': None}}),\n",
    "            apply_constraints_fn=self.apply_constraints_fn,\n",
    "            compute_reg_loss_fn=self.compute_reg_loss_fn,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data('dummy')\n",
    "model = load_ml_module('dummy')\n",
    "xs_train, ys_train = dm['train']\n",
    "xs_test, ys_test = dm['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955cda00d1144410bcb82fc77fc4949b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533e05248c294c9db20c8e54a070b016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity:  0.49600002\n"
     ]
    }
   ],
   "source": [
    "dcf = DiverseCF()\n",
    "dcf.init_fns()\n",
    "cf = dcf.generate_cf(xs_test[0], model.pred_fn)\n",
    "assert cf.shape == xs_test[0].shape\n",
    "\n",
    "partial_gen = partial(dcf.generate_cf, pred_fn=model.pred_fn)\n",
    "cfs = jax.vmap(partial_gen)(xs_test)\n",
    "\n",
    "print(\"Validity: \", keras.metrics.binary_accuracy(\n",
    "    (1 - model.pred_fn(xs_test)).round(),\n",
    "    model.pred_fn(cfs)\n",
    ").mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
