{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `ReLax` as a Recourse Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ReLax` contains implementations of various recourse methods, which are decoupled from the rest of `ReLax` library.\n",
    "We give users flexibility on how to use `ReLax`: \n",
    "\n",
    "* You can use the recourse pipeline in `ReLax` (\"one-liner\" for easy benchmarking recourse methods; see this [tutorial](getting_started.ipynb)).\n",
    "* You can use all of the recourse methods in `ReLax` without relying on the entire pipeline of `ReLax`.\n",
    "\n",
    "In this tutorial, we uncover the possibility of the second option by using recourse methods under `relax.methods` \n",
    "for debugging, diagnosing, interpreting your JAX models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Recourse Methods\n",
    "\n",
    "1. Non-parametric methods: These methods do not rely on any learned parameters. They generate counterfactuals solely based on the model's predictions and gradients. Examples in ReLax include `VanillaCF`, `DiverseCF` and `GrowingSphere` . These methods inherit from `CFModule`.\n",
    "\n",
    "2. Semi-parametric methods: These methods learn some parameters to aid in counterfactual generation, but do not learn a full counterfactual generation model. Examples in ReLax include `ProtoCF`, `CCHVAE` and `CLUE`. These methods inherit from `ParametricCFModule `.\n",
    "\n",
    "3. Parametric methods: These methods learn a full parametric model for counterfactual generation. The model is trained to generate counterfactuals that fool the model. Examples in ReLax include `CounterNet` and `VAECF`. These methods inherit from `ParametricCFModule`.\n",
    "\n",
    "\n",
    "|Method Type | Learned Parameters | Training Required | Example Methods | \n",
    "|-----|:-----|:---:|:-----:|\n",
    "|Non-parametric | None  |No   |`VanillaCF`, `DiverseCF`, `GrowingSphere` |\n",
    "|Semi-parametric| Some (θ) |Modest amount   |`ProtoCF`, `CCHVAE`, `CLUE` |\n",
    "|Parametric|Full generator model (φ)|Substantial amount|`CounterNet`, `VAECF` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usages\n",
    "\n",
    "At a high level, you can use the implemented methods in `ReLax` to generate *one* recourse explanation via three lines of code:\n",
    "\n",
    "```python\n",
    "from relax.methods import VanillaCF\n",
    "\n",
    "vcf = VanillaCF()\n",
    "# x is one data point. Shape: `(K)` or `(1, K)`\n",
    "cf = vcf.generate_cf(x, pred_fn=pred_fn)\n",
    "```\n",
    "\n",
    "Or generate a batch of recourse explanation via the `jax.vmap` primitive:\n",
    "\n",
    "```python\n",
    "...\n",
    "import functools as ft\n",
    "\n",
    "vcf_gen_fn = ft.partial(vcf.generate_cf, pred_fn=pred_fn)\n",
    "# xs is a batched data. Shape: `(N, K)`\n",
    "cfs = jax.vmap(vcf_gen_fn)(xs)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use parametric and semi-parametric methods, you can first train the model\n",
    "by calling `ParametricCF.train`, and then generate recourse explanations.\n",
    "Here is an example of using `ReLax` for `CCHVAE`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from relax.methods import CCHVAE\n",
    "\n",
    "cchvae = CCHVAE()\n",
    "cchvae.train(train_data) # Train CVAE before generation\n",
    "cf = cchvae.generate_cf(x, pred_fn=pred_fn) \n",
    "```\n",
    "\n",
    "Or generate a batch of recourse explanation via the `jax.vmap` primitive:\n",
    "\n",
    "```python\n",
    "...\n",
    "import functools as ft\n",
    "\n",
    "cchvae_gen_fn = ft.partial(cchvae.generate_cf, pred_fn=pred_fn)\n",
    "cfs = jax.vmap(cchvae_gen_fn)(xs) # Generate counterfactuals\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Recourse Methods\n",
    "\n",
    "Each recourse method in `ReLax` has an associated Config class that defines the set of supported configuration parameters. To configure a method, import and instantiate its Config class and pass it as the config parameter.\n",
    "\n",
    "For example, to configure `VanillaCF`:\n",
    "\n",
    "```Python\n",
    "from relax.methods import VanillaCF \n",
    "from relax.methods.vanilla import VanillaCFConfig\n",
    "\n",
    "config = VanillaCFConfig(\n",
    "  n_steps=100,\n",
    "  lr=0.1,\n",
    "  lambda_=0.1\n",
    ")\n",
    "\n",
    "vcf = VanillaCF(config)\n",
    "\n",
    "```\n",
    "Each Config class inherits from a `BaseConfig` that defines common options like n_steps. Method-specific parameters are defined on the individual Config classes.\n",
    "\n",
    "See the documentation for each recourse method for details on its supported configuration parameters. The Config class for a method can be imported from `relax.methods.[method_name]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also specify this config via a dictionary.\n",
    "\n",
    "```Python\n",
    "from relax.methods import VanillaCF\n",
    "\n",
    "config = {\n",
    "  \"n_steps\": 10,  \n",
    "  \"lambda_\": 0.1,\n",
    "  \"lr\": 0.1   \n",
    "}\n",
    "\n",
    "vcf = VanillaCF(config)\n",
    "```\n",
    "\n",
    "This config dictionary is passed to VanillaCF's __init__ method, which will set the specified parameters. Now our `VanillaCF` instance is configured to:\n",
    "\n",
    " * Number 10 optimization steps (n_steps=100)\n",
    " * Use 0.1 validity regularization for counterfactuals (lambda_=0.1)\n",
    " * Use a learning rate of 0.1 for optimization (lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement your Own Recourse Methods\n",
    "\n",
    "You can easily implement your own recourse methods and leverage `jax_relax` to scale the recourse generation. In this section, we implement a mock \"Recourse Method\", which add random perturbations to the input `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.methods.base import CFModule, BaseConfig\n",
    "from relax.utils import auto_reshaping, validate_configs\n",
    "from relax.import_essentials import *\n",
    "import relax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a configuration class for the random counterfactual module.\n",
    "This class inherits from the `BaseConfig` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCFConfig(BaseConfig):\n",
    "    max_perturb: float = 0.2 # Max perturbation allowed for RandomCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the random counterfactual module. This class inhertis from `CFModule` class. Importantly, you should override the `CFModule.generate_cf` and implement your CF generation procedure for **each** input (i.e., `shape=(k,)`, where `k` is the number of features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCF(CFModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict | RandomCFConfig = None,\n",
    "        name: str = None,\n",
    "    ):\n",
    "        if config is None:\n",
    "            config = RandomCFConfig()\n",
    "        config = validate_configs(config, RandomCFConfig)\n",
    "        name = \"RandomCF\" if name is None else name\n",
    "        super().__init__(config, name=name)\n",
    "\n",
    "    @auto_reshaping('x')\n",
    "    def generate_cf(\n",
    "        self,\n",
    "        x: Array, # Input data point\n",
    "        pred_fn: Callable = None, # Prediction function\n",
    "        y_target: Array = None,   # Target label\n",
    "        rng_key: jrand.PRNGKey = None, # Random key\n",
    "        **kwargs,\n",
    "    ) -> Array:\n",
    "        # Generate random perturbations in the range of [-max_perturb, max_perturb].\n",
    "        x_cf = x + jrand.uniform(rng_key, x.shape, \n",
    "                                 minval=-self.config.max_perturb, \n",
    "                                 maxval=self.config.max_perturb)\n",
    "        return x_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can easily use `jax-relax` to generate recourse explanations at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                       |   acc |   validity |   proximity |\n",
      "|:----------------------|------:|-----------:|------------:|\n",
      "| ('dummy', 'RandomCF') | 0.983 |  0.0599999 |    0.997049 |\n"
     ]
    }
   ],
   "source": [
    "rand_cf = RandomCF()\n",
    "exps = relax.generate_cf_explanations(\n",
    "    rand_cf, relax.load_data('dummy'), relax.load_ml_module('dummy').pred_fn, \n",
    ")\n",
    "relax.benchmark_cfs([exps])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
